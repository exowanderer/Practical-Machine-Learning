{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Clustering - Mean Shift\n",
    "\n",
    "K-Means is called \"flat clustering\" and required us to specify how many clusters we think exists\n",
    "\n",
    "Mean shift estimates how many clusters exists and then finds the centers of those clusters\n",
    "\n",
    "Mean Shift (MS) starts by placing a cluster center at the \"1st\" or \"1st random\" feature point.\n",
    "- It then  assigns a \"bandwidth\" or \"radius\" around each initial cluster center and determines how many features are within the \"bandwidth\" or \"radius\".\n",
    "    - This is done for every single \"cluster center\".\n",
    "\n",
    "After taking the mean of all of the data points in the cluster center + radius (bandwidth), it assigns this average as the new cluster center.\n",
    "    - MS again assigned a bandwidth around that new cluster center and iterates until convergence \n",
    "       - convergence means difference between old and new cluster center is below epsilon\n",
    "\n",
    "As the cluster center moves around looking for convergence, it finds new feature points.  \n",
    "These new features points change the cluster center (maybe they should change the bandwidth too(?).\n",
    "\n",
    "The method allows such that if you start from any point any given cluster, MS will find the same set of feature points within the same cluster (cluster center, radius).  \n",
    "\n",
    "Once MS finds no new feature points and stops moving the cluster center, it has reached convergence.\n",
    "\n",
    "But there are known feature points outside of this cluster.  This must start again using the feature points that are outside the given cluster.\n",
    "- This creates a new cluster (i.e. MS determines the number of clusters && their centers)\n",
    "    \n",
    "This new cluster iterates to convergence again.  If there are more more feature points outside BOTH clusters, then MS will make a third cluster.\n",
    "\n",
    "If all feature points are accounted for by known clusters with centers and bandwidths, then MS has completed optimization\n",
    "\n",
    "---\n",
    "What if the clustering is not obvious?\n",
    "---\n",
    "\n",
    "MS can make sets of concentric bandwidths around the same clustering center, but with weights assigned to them.\n",
    "Such that the set of feature sets has 1 given center, but the points furthest away from that center are weighted less than the feature points that are closest to the center.\n",
    "- for a 'cluster' with 3 radii, the weights could be (3,2,1) for (nearest, middlest, furthest), respectively.\n",
    "- could also penalize in some sort of squared error fashion too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Simple Example of Hierarchical Clustering with Mean Shift\n",
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn.cluster import MeanShift\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import style\n",
    "style.use('fivethirtyeight')\n",
    "\n",
    "nsamples= 100\n",
    "centers = [[1,1,1], [5,5,5], [3,10,10]]\n",
    "X, _    = make_blobs(n_samples=nsamples, centers=centers, cluster_std=1)\n",
    "\n",
    "ms  = MeanShift()\n",
    "ms.fit(X)\n",
    "\n",
    "labels          = ms.labels_\n",
    "cluster_centers = ms.cluster_centers_\n",
    "\n",
    "print(cluster_centers)\n",
    "\n",
    "n_clusters_ = len(np.unique(labels))\n",
    "\n",
    "print(\"Number of estimated clusters:\", n_clusters_)\n",
    "\n",
    "colors = 10*plt.rcParams['axes.color_cycle']\n",
    "\n",
    "fig = plt.figure()\n",
    "ax  = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "for i in range(len(X)):\n",
    "    ax.scatter(X[i][0], X[i][1], X[i][2], c=colors[labels[i]], marker='o')\n",
    "\n",
    "ax.scatter(cluster_centers[:,0], cluster_centers[:,1], cluster_centers[:,2], \n",
    "               marker='x', color='k', s=150, lw=5, zorder=10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "print(n_clusters_)\n",
    "print(centers)\n",
    "print(cluster_centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Titanic Data Set\n",
    "---\n",
    "\n",
    "We assumed that the titanic data set would split into 2 groups because either survived or died; and we assumed that the more wealthy a passenger was, the more likely they were to have survived\n",
    "\n",
    "Using MeanShift instead of K-Means lets us remove that assumption and ask not only \"where\" are the cluster centers, but how many are there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanfraine/anaconda/lib/python3.5/site-packages/matplotlib/__init__.py:1028: UserWarning: Illegal line #312\n",
      "\t\"                               legend, else a rectangle\n",
      "\"\n",
      "\tin file \"/Users/jonathanfraine/anaconda/lib/python3.5/site-packages/matplotlib/mpl-data/matplotlibrc\"\n",
      "  warnings.warn('Illegal %s' % error_details)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing, cross_validation\n",
    "from sklearn.cluster import MeanShift\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import style\n",
    "style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Pclass Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
    "survival Survival (0 = No; 1 = Yes)\n",
    "name Name\n",
    "sex Sex\n",
    "age Age\n",
    "sibsp Number of Siblings/Spouses Aboard\n",
    "parch Number of Parents/Children Aboard\n",
    "ticket Ticket Number\n",
    "fare Passenger Fare (British pound)\n",
    "cabin Cabin\n",
    "embarked Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
    "boat Lifeboat\n",
    "body Body Identification Number\n",
    "home.dest Home/Destination\n",
    "'''\n",
    "\n",
    "\n",
    "# https://pythonprogramming.net/static/downloads/machine-learning-data/titanic.xls\n",
    "df = pd.read_excel('titanic.xls')\n",
    "original_df = pd.DataFrame.copy(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.drop(['body','name'], 1, inplace=True)\n",
    "df.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def handle_non_numerical_data(df):\n",
    "    \n",
    "    # handling non-numerical data: must convert.\n",
    "    columns = df.columns.values\n",
    "\n",
    "    for column in columns:\n",
    "        text_digit_vals = {}\n",
    "        def convert_to_int(val):\n",
    "            return text_digit_vals[val]\n",
    "\n",
    "        #print(column,df[column].dtype)\n",
    "        if df[column].dtype != np.int64 and df[column].dtype != np.float64:\n",
    "            \n",
    "            column_contents = df[column].values.tolist()\n",
    "            #finding just the uniques\n",
    "            unique_elements = set(column_contents)\n",
    "            # great, found them. \n",
    "            x = 0\n",
    "            for unique in unique_elements:\n",
    "                if unique not in text_digit_vals:\n",
    "                    # creating dict that contains new\n",
    "                    # id per unique string\n",
    "                    text_digit_vals[unique] = x\n",
    "                    x+=1\n",
    "            # now we map the new \"id\" vlaue\n",
    "            # to replace the string. \n",
    "            df[column] = list(map(convert_to_int,df[column]))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = handle_non_numerical_data(df)\n",
    "df.drop(['ticket','home.dest'], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array(df.drop(['survived'], 1).astype(float))\n",
    "X = preprocessing.scale(X)\n",
    "y = np.array(df['survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MeanShift(bandwidth=None, bin_seeding=False, cluster_all=True, min_bin_freq=1,\n",
       "     n_jobs=1, seeds=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms = MeanShift()\n",
    "ms.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels          = ms.labels_\n",
    "cluster_centers = ms.cluster_centers_\n",
    "n_clusters      = len(cluster_centers)\n",
    "n_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanfraine/anaconda/lib/python3.5/site-packages/pandas/core/indexing.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df['cluster_group'] = np.nan\n",
    "\n",
    "for i,label in enumerate(labels):\n",
    "    original_df['cluster_group'].iloc[i] = label\n",
    "\n",
    "n_clusters_ = len(np.unique(labels))\n",
    "n_clusters_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.3685897435897436, 1: 1.0, 2: 0.7391304347826086, 3: 0.1}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survival_rates = {}\n",
    "for clusterNow in range(n_clusters_):\n",
    "    temp_df = original_df[(original_df['cluster_group'] == float(clusterNow))]\n",
    "    \n",
    "    # Define Survival Clusters\n",
    "    survival_cluster = temp_df[(temp_df['survived'] == 1)]\n",
    "    survival_rate    = len(survival_cluster) / len(temp_df)\n",
    "    survival_rates[clusterNow] = survival_rate\n",
    "\n",
    "survival_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster:  0\n",
      "0             pclass     survived          age        sibsp        parch  \\\n",
      "count  1309.000000  1309.000000  1046.000000  1309.000000  1309.000000   \n",
      "mean      2.294882     0.381971    29.881135     0.498854     0.385027   \n",
      "std       0.837836     0.486055    14.413500     1.041658     0.865560   \n",
      "min       1.000000     0.000000     0.166700     0.000000     0.000000   \n",
      "25%       2.000000     0.000000          NaN     0.000000     0.000000   \n",
      "50%       3.000000     0.000000          NaN     0.000000     0.000000   \n",
      "75%       3.000000     1.000000          NaN     1.000000     0.000000   \n",
      "max       3.000000     1.000000    80.000000     8.000000     9.000000   \n",
      "\n",
      "              fare        body  cluster_group  \n",
      "count  1308.000000  121.000000    1309.000000  \n",
      "mean     33.295479  160.809917       0.097021  \n",
      "std      51.758668   97.696922       0.451534  \n",
      "min       0.000000    1.000000       0.000000  \n",
      "25%            NaN         NaN       0.000000  \n",
      "50%            NaN         NaN       0.000000  \n",
      "75%            NaN         NaN       0.000000  \n",
      "max     512.329200  328.000000       3.000000  \n",
      "\n",
      "Cluster:  1\n",
      "1             pclass     survived          age        sibsp        parch  \\\n",
      "count  1309.000000  1309.000000  1046.000000  1309.000000  1309.000000   \n",
      "mean      2.294882     0.381971    29.881135     0.498854     0.385027   \n",
      "std       0.837836     0.486055    14.413500     1.041658     0.865560   \n",
      "min       1.000000     0.000000     0.166700     0.000000     0.000000   \n",
      "25%       2.000000     0.000000          NaN     0.000000     0.000000   \n",
      "50%       3.000000     0.000000          NaN     0.000000     0.000000   \n",
      "75%       3.000000     1.000000          NaN     1.000000     0.000000   \n",
      "max       3.000000     1.000000    80.000000     8.000000     9.000000   \n",
      "\n",
      "              fare        body  cluster_group  \n",
      "count  1308.000000  121.000000    1309.000000  \n",
      "mean     33.295479  160.809917       0.097021  \n",
      "std      51.758668   97.696922       0.451534  \n",
      "min       0.000000    1.000000       0.000000  \n",
      "25%            NaN         NaN       0.000000  \n",
      "50%            NaN         NaN       0.000000  \n",
      "75%            NaN         NaN       0.000000  \n",
      "max     512.329200  328.000000       3.000000  \n",
      "\n",
      "Cluster:  2\n",
      "2             pclass     survived          age        sibsp        parch  \\\n",
      "count  1309.000000  1309.000000  1046.000000  1309.000000  1309.000000   \n",
      "mean      2.294882     0.381971    29.881135     0.498854     0.385027   \n",
      "std       0.837836     0.486055    14.413500     1.041658     0.865560   \n",
      "min       1.000000     0.000000     0.166700     0.000000     0.000000   \n",
      "25%       2.000000     0.000000          NaN     0.000000     0.000000   \n",
      "50%       3.000000     0.000000          NaN     0.000000     0.000000   \n",
      "75%       3.000000     1.000000          NaN     1.000000     0.000000   \n",
      "max       3.000000     1.000000    80.000000     8.000000     9.000000   \n",
      "\n",
      "              fare        body  cluster_group  \n",
      "count  1308.000000  121.000000    1309.000000  \n",
      "mean     33.295479  160.809917       0.097021  \n",
      "std      51.758668   97.696922       0.451534  \n",
      "min       0.000000    1.000000       0.000000  \n",
      "25%            NaN         NaN       0.000000  \n",
      "50%            NaN         NaN       0.000000  \n",
      "75%            NaN         NaN       0.000000  \n",
      "max     512.329200  328.000000       3.000000  \n",
      "\n",
      "Cluster:  3\n",
      "3             pclass     survived          age        sibsp        parch  \\\n",
      "count  1309.000000  1309.000000  1046.000000  1309.000000  1309.000000   \n",
      "mean      2.294882     0.381971    29.881135     0.498854     0.385027   \n",
      "std       0.837836     0.486055    14.413500     1.041658     0.865560   \n",
      "min       1.000000     0.000000     0.166700     0.000000     0.000000   \n",
      "25%       2.000000     0.000000          NaN     0.000000     0.000000   \n",
      "50%       3.000000     0.000000          NaN     0.000000     0.000000   \n",
      "75%       3.000000     1.000000          NaN     1.000000     0.000000   \n",
      "max       3.000000     1.000000    80.000000     8.000000     9.000000   \n",
      "\n",
      "              fare        body  cluster_group  \n",
      "count  1308.000000  121.000000    1309.000000  \n",
      "mean     33.295479  160.809917       0.097021  \n",
      "std      51.758668   97.696922       0.451534  \n",
      "min       0.000000    1.000000       0.000000  \n",
      "25%            NaN         NaN       0.000000  \n",
      "50%            NaN         NaN       0.000000  \n",
      "75%            NaN         NaN       0.000000  \n",
      "max     512.329200  328.000000       3.000000  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanfraine/anaconda/lib/python3.5/site-packages/numpy/lib/function_base.py:3834: RuntimeWarning: Invalid value encountered in percentile\n",
      "  RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "for clusterNow in range(n_clusters_):\n",
    "    # print(clusterNow, original_df[original_df['cluster_group'] == clusterNow]['pclass'].drop_duplicates().values, survival_rates[clusterNow]*100, end='\\n\\n')\n",
    "    print('Cluster: ', clusterNow)\n",
    "    print(clusterNow, original_df.describe(), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colors = 10*plt.rcParams['axes.color_cycle']\n",
    "\n",
    "fig = plt.figure()\n",
    "ax  = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "for i in range(len(X)):\n",
    "    ax.scatter(X[i][0], X[i][1], X[i][6], c=colors[labels[i]], marker='o')\n",
    "\n",
    "ax.scatter(cluster_centers[:,0], cluster_centers[:,1], cluster_centers[:,3], \n",
    "               marker='x', color='k', s=150, lw=5, zorder=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k in np.unique(labels):\n",
    "    print(np.where(labels == k)[0].sum())"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
